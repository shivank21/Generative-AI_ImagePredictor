{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bba99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90b7563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Shivank garg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e071b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shivank garg\\AppData\\Local\\Temp\\ipykernel_21612\\161675896.py:1: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframe= pd.read_csv(\"train.csv\", header=None)\n",
      "C:\\Users\\Shivank garg\\AppData\\Local\\Temp\\ipykernel_21612\\161675896.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dftest= pd.read_csv(\"test.csv\", header=None)\n"
     ]
    }
   ],
   "source": [
    "dataframe= pd.read_csv(\"train.csv\", header=None)\n",
    "dftest= pd.read_csv(\"test.csv\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918e798b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1191</th>\n",
       "      <th>1192</th>\n",
       "      <th>1193</th>\n",
       "      <th>1194</th>\n",
       "      <th>1195</th>\n",
       "      <th>1196</th>\n",
       "      <th>1197</th>\n",
       "      <th>1198</th>\n",
       "      <th>1199</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>labels</td>\n",
       "      <td>f_0</td>\n",
       "      <td>f_1</td>\n",
       "      <td>f_2</td>\n",
       "      <td>f_3</td>\n",
       "      <td>f_4</td>\n",
       "      <td>f_5</td>\n",
       "      <td>f_6</td>\n",
       "      <td>f_7</td>\n",
       "      <td>f_8</td>\n",
       "      <td>...</td>\n",
       "      <td>f_1190</td>\n",
       "      <td>f_1191</td>\n",
       "      <td>f_1192</td>\n",
       "      <td>f_1193</td>\n",
       "      <td>f_1194</td>\n",
       "      <td>f_1195</td>\n",
       "      <td>f_1196</td>\n",
       "      <td>f_1197</td>\n",
       "      <td>f_1198</td>\n",
       "      <td>f_1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.0338754847514076</td>\n",
       "      <td>0.9784459341144622</td>\n",
       "      <td>-0.1421308401166783</td>\n",
       "      <td>-0.17711703501154927</td>\n",
       "      <td>-1.4706840047636902</td>\n",
       "      <td>1.6695623289421941</td>\n",
       "      <td>-0.19652975909853684</td>\n",
       "      <td>-0.1252386301384724</td>\n",
       "      <td>-0.4522844255730295</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1112658145100465</td>\n",
       "      <td>0.7160835790790151</td>\n",
       "      <td>0.060039060398674786</td>\n",
       "      <td>0.301279104628461</td>\n",
       "      <td>-1.1748459564577958</td>\n",
       "      <td>-1.076498490875714</td>\n",
       "      <td>-0.06945243165009196</td>\n",
       "      <td>-0.6040120219413277</td>\n",
       "      <td>-2.179175631864767</td>\n",
       "      <td>0.5580031551308428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.34883507271702585</td>\n",
       "      <td>0.29481456283081336</td>\n",
       "      <td>-0.5575766736236175</td>\n",
       "      <td>-2.0207727956959505</td>\n",
       "      <td>-1.2347153930615196</td>\n",
       "      <td>1.6339301260293642</td>\n",
       "      <td>-1.6806584041297072</td>\n",
       "      <td>-0.3581457219894779</td>\n",
       "      <td>0.16612181759450426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735240428445085</td>\n",
       "      <td>0.829781288146005</td>\n",
       "      <td>1.521941355809489</td>\n",
       "      <td>1.3479456224981563</td>\n",
       "      <td>0.7545052782333206</td>\n",
       "      <td>1.3306420619963777</td>\n",
       "      <td>-0.754453180396377</td>\n",
       "      <td>0.5829564533383925</td>\n",
       "      <td>0.2526709780911331</td>\n",
       "      <td>1.4958698108055448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113247803879688</td>\n",
       "      <td>-0.607725685220181</td>\n",
       "      <td>-0.9477910279408399</td>\n",
       "      <td>0.8308509405069512</td>\n",
       "      <td>0.9982909738046802</td>\n",
       "      <td>0.49832088627350685</td>\n",
       "      <td>-1.493958360949691</td>\n",
       "      <td>0.7895718864951502</td>\n",
       "      <td>-1.3110180776845535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1046981689668915</td>\n",
       "      <td>0.6161892846239375</td>\n",
       "      <td>-1.0359528971009342</td>\n",
       "      <td>2.111387146820228</td>\n",
       "      <td>-0.984414620904498</td>\n",
       "      <td>1.1480756131093413</td>\n",
       "      <td>-1.433554203291222</td>\n",
       "      <td>0.2433724502194554</td>\n",
       "      <td>0.17008343495959583</td>\n",
       "      <td>1.274795045377175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.2233209192853869</td>\n",
       "      <td>-0.4790480627697671</td>\n",
       "      <td>-1.9257889089567417</td>\n",
       "      <td>1.680376707475607</td>\n",
       "      <td>0.021840467070529515</td>\n",
       "      <td>-1.4533069034209085</td>\n",
       "      <td>0.6055593380187781</td>\n",
       "      <td>-0.019024011988712706</td>\n",
       "      <td>1.065447664850538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3602369794340369</td>\n",
       "      <td>-1.957863263193831</td>\n",
       "      <td>-0.12338374704090385</td>\n",
       "      <td>1.5053289508509657</td>\n",
       "      <td>0.6602904672299815</td>\n",
       "      <td>-1.7694428174974057</td>\n",
       "      <td>-0.547756262665183</td>\n",
       "      <td>-0.568121575372889</td>\n",
       "      <td>0.24464460762158835</td>\n",
       "      <td>0.9821155381726155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                     1                    2                    3     \\\n",
       "0  labels                   f_0                  f_1                  f_2   \n",
       "1       0   -2.0338754847514076   0.9784459341144622  -0.1421308401166783   \n",
       "2       1  -0.34883507271702585  0.29481456283081336  -0.5575766736236175   \n",
       "3       1     0.113247803879688   -0.607725685220181  -0.9477910279408399   \n",
       "4       0    1.2233209192853869  -0.4790480627697671  -1.9257889089567417   \n",
       "\n",
       "                   4                     5                    6     \\\n",
       "0                   f_3                   f_4                  f_5   \n",
       "1  -0.17711703501154927   -1.4706840047636902   1.6695623289421941   \n",
       "2   -2.0207727956959505   -1.2347153930615196   1.6339301260293642   \n",
       "3    0.8308509405069512    0.9982909738046802  0.49832088627350685   \n",
       "4     1.680376707475607  0.021840467070529515  -1.4533069034209085   \n",
       "\n",
       "                   7                      8                    9     ...  \\\n",
       "0                   f_6                    f_7                  f_8  ...   \n",
       "1  -0.19652975909853684    -0.1252386301384724  -0.4522844255730295  ...   \n",
       "2   -1.6806584041297072    -0.3581457219894779  0.16612181759450426  ...   \n",
       "3    -1.493958360949691     0.7895718864951502  -1.3110180776845535  ...   \n",
       "4    0.6055593380187781  -0.019024011988712706    1.065447664850538  ...   \n",
       "\n",
       "                  1191                1192                  1193  \\\n",
       "0               f_1190              f_1191                f_1192   \n",
       "1  -1.1112658145100465  0.7160835790790151  0.060039060398674786   \n",
       "2    0.735240428445085   0.829781288146005     1.521941355809489   \n",
       "3   0.1046981689668915  0.6161892846239375   -1.0359528971009342   \n",
       "4   0.3602369794340369  -1.957863263193831  -0.12338374704090385   \n",
       "\n",
       "                 1194                 1195                 1196  \\\n",
       "0              f_1193               f_1194               f_1195   \n",
       "1   0.301279104628461  -1.1748459564577958   -1.076498490875714   \n",
       "2  1.3479456224981563   0.7545052782333206   1.3306420619963777   \n",
       "3   2.111387146820228   -0.984414620904498   1.1480756131093413   \n",
       "4  1.5053289508509657   0.6602904672299815  -1.7694428174974057   \n",
       "\n",
       "                   1197                 1198                 1199  \\\n",
       "0                f_1196               f_1197               f_1198   \n",
       "1  -0.06945243165009196  -0.6040120219413277   -2.179175631864767   \n",
       "2    -0.754453180396377   0.5829564533383925   0.2526709780911331   \n",
       "3    -1.433554203291222   0.2433724502194554  0.17008343495959583   \n",
       "4    -0.547756262665183   -0.568121575372889  0.24464460762158835   \n",
       "\n",
       "                 1200  \n",
       "0              f_1199  \n",
       "1  0.5580031551308428  \n",
       "2  1.4958698108055448  \n",
       "3   1.274795045377175  \n",
       "4  0.9821155381726155  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21b4f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = dataframe.iloc[1:, 1:1201].astype(float)\n",
    "Ytrain = dataframe.iloc[1:, 0].astype(float)\n",
    "Xtest = dftest.iloc[1:, 1:1201].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d4ded0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1191</th>\n",
       "      <th>1192</th>\n",
       "      <th>1193</th>\n",
       "      <th>1194</th>\n",
       "      <th>1195</th>\n",
       "      <th>1196</th>\n",
       "      <th>1197</th>\n",
       "      <th>1198</th>\n",
       "      <th>1199</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.033875</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>-0.142131</td>\n",
       "      <td>-0.177117</td>\n",
       "      <td>-1.470684</td>\n",
       "      <td>1.669562</td>\n",
       "      <td>-0.196530</td>\n",
       "      <td>-0.125239</td>\n",
       "      <td>-0.452284</td>\n",
       "      <td>-0.128052</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.111266</td>\n",
       "      <td>0.716084</td>\n",
       "      <td>0.060039</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>-1.174846</td>\n",
       "      <td>-1.076498</td>\n",
       "      <td>-0.069452</td>\n",
       "      <td>-0.604012</td>\n",
       "      <td>-2.179176</td>\n",
       "      <td>0.558003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.348835</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>-0.557577</td>\n",
       "      <td>-2.020773</td>\n",
       "      <td>-1.234715</td>\n",
       "      <td>1.633930</td>\n",
       "      <td>-1.680658</td>\n",
       "      <td>-0.358146</td>\n",
       "      <td>0.166122</td>\n",
       "      <td>-1.656990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.829781</td>\n",
       "      <td>1.521941</td>\n",
       "      <td>1.347946</td>\n",
       "      <td>0.754505</td>\n",
       "      <td>1.330642</td>\n",
       "      <td>-0.754453</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>0.252671</td>\n",
       "      <td>1.495870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.113248</td>\n",
       "      <td>-0.607726</td>\n",
       "      <td>-0.947791</td>\n",
       "      <td>0.830851</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>-1.493958</td>\n",
       "      <td>0.789572</td>\n",
       "      <td>-1.311018</td>\n",
       "      <td>0.848524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104698</td>\n",
       "      <td>0.616189</td>\n",
       "      <td>-1.035953</td>\n",
       "      <td>2.111387</td>\n",
       "      <td>-0.984415</td>\n",
       "      <td>1.148076</td>\n",
       "      <td>-1.433554</td>\n",
       "      <td>0.243372</td>\n",
       "      <td>0.170083</td>\n",
       "      <td>1.274795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.223321</td>\n",
       "      <td>-0.479048</td>\n",
       "      <td>-1.925789</td>\n",
       "      <td>1.680377</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-1.453307</td>\n",
       "      <td>0.605559</td>\n",
       "      <td>-0.019024</td>\n",
       "      <td>1.065448</td>\n",
       "      <td>0.717341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360237</td>\n",
       "      <td>-1.957863</td>\n",
       "      <td>-0.123384</td>\n",
       "      <td>1.505329</td>\n",
       "      <td>0.660290</td>\n",
       "      <td>-1.769443</td>\n",
       "      <td>-0.547756</td>\n",
       "      <td>-0.568122</td>\n",
       "      <td>0.244645</td>\n",
       "      <td>0.982116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.160109</td>\n",
       "      <td>0.422684</td>\n",
       "      <td>-0.308029</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.432854</td>\n",
       "      <td>0.608348</td>\n",
       "      <td>0.193832</td>\n",
       "      <td>1.035091</td>\n",
       "      <td>-0.538868</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>1.441766</td>\n",
       "      <td>0.212572</td>\n",
       "      <td>-0.994721</td>\n",
       "      <td>1.143999</td>\n",
       "      <td>-2.166923</td>\n",
       "      <td>-1.199248</td>\n",
       "      <td>-1.028636</td>\n",
       "      <td>0.752791</td>\n",
       "      <td>0.317169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>1.157565</td>\n",
       "      <td>-0.142219</td>\n",
       "      <td>1.043992</td>\n",
       "      <td>1.144946</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>0.248978</td>\n",
       "      <td>-1.505100</td>\n",
       "      <td>-0.874137</td>\n",
       "      <td>-1.782724</td>\n",
       "      <td>0.261597</td>\n",
       "      <td>...</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>-0.255793</td>\n",
       "      <td>-0.154838</td>\n",
       "      <td>0.413029</td>\n",
       "      <td>-0.482939</td>\n",
       "      <td>-1.277953</td>\n",
       "      <td>-0.445082</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>-0.924614</td>\n",
       "      <td>-0.432462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>1.424709</td>\n",
       "      <td>0.235910</td>\n",
       "      <td>1.356778</td>\n",
       "      <td>1.368099</td>\n",
       "      <td>-0.318862</td>\n",
       "      <td>1.039765</td>\n",
       "      <td>-0.986854</td>\n",
       "      <td>-0.330184</td>\n",
       "      <td>-1.383120</td>\n",
       "      <td>1.243559</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424709</td>\n",
       "      <td>-1.066107</td>\n",
       "      <td>0.881258</td>\n",
       "      <td>-0.488691</td>\n",
       "      <td>-1.281223</td>\n",
       "      <td>-1.213291</td>\n",
       "      <td>0.122692</td>\n",
       "      <td>1.175627</td>\n",
       "      <td>-1.145360</td>\n",
       "      <td>0.451026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>-0.375687</td>\n",
       "      <td>1.524455</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>-0.007917</td>\n",
       "      <td>0.073809</td>\n",
       "      <td>-0.906909</td>\n",
       "      <td>-1.254247</td>\n",
       "      <td>1.606182</td>\n",
       "      <td>0.298557</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028349</td>\n",
       "      <td>-0.968204</td>\n",
       "      <td>-1.233815</td>\n",
       "      <td>1.626613</td>\n",
       "      <td>-0.191802</td>\n",
       "      <td>1.115823</td>\n",
       "      <td>0.380284</td>\n",
       "      <td>-0.293960</td>\n",
       "      <td>0.135104</td>\n",
       "      <td>1.381434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>-0.478238</td>\n",
       "      <td>1.666142</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>-0.428752</td>\n",
       "      <td>-0.362771</td>\n",
       "      <td>1.798104</td>\n",
       "      <td>-0.214314</td>\n",
       "      <td>0.775400</td>\n",
       "      <td>-0.379267</td>\n",
       "      <td>0.725914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.428752</td>\n",
       "      <td>-1.121552</td>\n",
       "      <td>-0.379267</td>\n",
       "      <td>-0.593705</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>1.765114</td>\n",
       "      <td>0.313533</td>\n",
       "      <td>-0.329781</td>\n",
       "      <td>-1.220524</td>\n",
       "      <td>0.033114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>-0.750874</td>\n",
       "      <td>0.267008</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.179867</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.303999</td>\n",
       "      <td>-0.279173</td>\n",
       "      <td>1.731765</td>\n",
       "      <td>0.564925</td>\n",
       "      <td>1.508328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303999</td>\n",
       "      <td>-0.850180</td>\n",
       "      <td>0.937321</td>\n",
       "      <td>-1.594972</td>\n",
       "      <td>1.036626</td>\n",
       "      <td>1.582807</td>\n",
       "      <td>1.036626</td>\n",
       "      <td>-0.254346</td>\n",
       "      <td>0.664230</td>\n",
       "      <td>1.831071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5250 rows × 1200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7     \\\n",
       "1    -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562 -0.196530   \n",
       "2    -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930 -1.680658   \n",
       "3     0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321 -1.493958   \n",
       "4     1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307  0.605559   \n",
       "5     0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348  0.193832   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5246  1.157565 -0.142219  1.043992  1.144946  1.195423  0.248978 -1.505100   \n",
       "5247  1.424709  0.235910  1.356778  1.368099 -0.318862  1.039765 -0.986854   \n",
       "5248 -0.375687  1.524455  0.012514 -0.007917  0.073809 -0.906909 -1.254247   \n",
       "5249 -0.478238  1.666142  0.049609 -0.428752 -0.362771  1.798104 -0.214314   \n",
       "5250 -0.750874  0.267008 -0.155041 -0.179867 -0.155041 -0.303999 -0.279173   \n",
       "\n",
       "          8         9         10    ...      1191      1192      1193  \\\n",
       "1    -0.125239 -0.452284 -0.128052  ... -1.111266  0.716084  0.060039   \n",
       "2    -0.358146  0.166122 -1.656990  ...  0.735240  0.829781  1.521941   \n",
       "3     0.789572 -1.311018  0.848524  ...  0.104698  0.616189 -1.035953   \n",
       "4    -0.019024  1.065448  0.717341  ...  0.360237 -1.957863 -0.123384   \n",
       "5     1.035091 -0.538868  0.778445  ...  0.416629  1.441766  0.212572   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5246 -0.874137 -1.782724  0.261597  ...  1.195423 -0.255793 -0.154838   \n",
       "5247 -0.330184 -1.383120  1.243559  ...  1.424709 -1.066107  0.881258   \n",
       "5248  1.606182  0.298557  0.053378  ... -0.028349 -0.968204 -1.233815   \n",
       "5249  0.775400 -0.379267  0.725914  ... -0.428752 -1.121552 -0.379267   \n",
       "5250  1.731765  0.564925  1.508328  ... -0.303999 -0.850180  0.937321   \n",
       "\n",
       "          1194      1195      1196      1197      1198      1199      1200  \n",
       "1     0.301279 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
       "2     1.347946  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
       "3     2.111387 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
       "4     1.505329  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
       "5    -0.994721  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5246  0.413029 -0.482939 -1.277953 -0.445082  1.195423 -0.924614 -0.432462  \n",
       "5247 -0.488691 -1.281223 -1.213291  0.122692  1.175627 -1.145360  0.451026  \n",
       "5248  1.626613 -0.191802  1.115823  0.380284 -0.293960  0.135104  1.381434  \n",
       "5249 -0.593705  0.049609  1.765114  0.313533 -0.329781 -1.220524  0.033114  \n",
       "5250 -1.594972  1.036626  1.582807  1.036626 -0.254346  0.664230  1.831071  \n",
       "\n",
       "[5250 rows x 1200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc570e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "5       0\n",
       "       ..\n",
       "5246    0\n",
       "5247    0\n",
       "5248    1\n",
       "5249    1\n",
       "5250    1\n",
       "Name: 0, Length: 5250, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b77f37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=1200, activation='relu')) \n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a09fb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               307456    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 350,721\n",
      "Trainable params: 350,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad2ee9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " from sklearn.model_selection import train_test_split\n",
    " X_train, X_val, Y_train, Y_val = train_test_split(Xtrain,Ytrain, test_size=0.2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f93c87fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "132/132 [==============================] - 3s 15ms/step - loss: 0.3369 - accuracy: 0.8400 - val_loss: 0.3235 - val_accuracy: 0.8476\n",
      "Epoch 2/25\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 0.0970 - accuracy: 0.9652 - val_loss: 0.4985 - val_accuracy: 0.8219\n",
      "Epoch 3/25\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.0308 - accuracy: 0.9926 - val_loss: 0.6878 - val_accuracy: 0.8457\n",
      "Epoch 4/25\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.7354 - val_accuracy: 0.8448\n",
      "Epoch 5/25\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.9313 - val_accuracy: 0.8438\n",
      "Epoch 6/25\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0489 - val_accuracy: 0.8362\n",
      "Epoch 7/25\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 1.3937e-04 - accuracy: 1.0000 - val_loss: 1.1010 - val_accuracy: 0.8381\n",
      "Epoch 8/25\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 8.2745e-05 - accuracy: 1.0000 - val_loss: 1.1365 - val_accuracy: 0.8371\n",
      "Epoch 9/25\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 5.9995e-05 - accuracy: 1.0000 - val_loss: 1.1663 - val_accuracy: 0.8381\n",
      "Epoch 10/25\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 4.6075e-05 - accuracy: 1.0000 - val_loss: 1.1924 - val_accuracy: 0.8381\n",
      "Epoch 11/25\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 3.6568e-05 - accuracy: 1.0000 - val_loss: 1.2153 - val_accuracy: 0.8381\n",
      "Epoch 12/25\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 2.9759e-05 - accuracy: 1.0000 - val_loss: 1.2362 - val_accuracy: 0.8371\n",
      "Epoch 13/25\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 2.4609e-05 - accuracy: 1.0000 - val_loss: 1.2560 - val_accuracy: 0.8362\n",
      "Epoch 14/25\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 2.0655e-05 - accuracy: 1.0000 - val_loss: 1.2741 - val_accuracy: 0.8362\n",
      "Epoch 15/25\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 1.7567e-05 - accuracy: 1.0000 - val_loss: 1.2913 - val_accuracy: 0.8352\n",
      "Epoch 16/25\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 1.5061e-05 - accuracy: 1.0000 - val_loss: 1.3076 - val_accuracy: 0.8352\n",
      "Epoch 17/25\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 1.3027e-05 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.8352\n",
      "Epoch 18/25\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 1.1360e-05 - accuracy: 1.0000 - val_loss: 1.3372 - val_accuracy: 0.8343\n",
      "Epoch 19/25\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 9.9652e-06 - accuracy: 1.0000 - val_loss: 1.3512 - val_accuracy: 0.8343\n",
      "Epoch 20/25\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 8.7823e-06 - accuracy: 1.0000 - val_loss: 1.3649 - val_accuracy: 0.8333\n",
      "Epoch 21/25\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 7.7799e-06 - accuracy: 1.0000 - val_loss: 1.3776 - val_accuracy: 0.8333\n",
      "Epoch 22/25\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 6.9267e-06 - accuracy: 1.0000 - val_loss: 1.3903 - val_accuracy: 0.8352\n",
      "Epoch 23/25\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 6.1749e-06 - accuracy: 1.0000 - val_loss: 1.4025 - val_accuracy: 0.8352\n",
      "Epoch 24/25\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 5.5306e-06 - accuracy: 1.0000 - val_loss: 1.4143 - val_accuracy: 0.8352\n",
      "Epoch 25/25\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 4.9720e-06 - accuracy: 1.0000 - val_loss: 1.4257 - val_accuracy: 0.8352\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,epochs=25,validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd7c0d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.76825371, -0.7297375 , -0.74909348, ..., -0.34849333,\n",
       "         0.00731146, -0.03518256],\n",
       "       [-1.82920217, -0.91172681, -0.98808716, ...,  0.42681018,\n",
       "        -1.18005351, -2.48695353],\n",
       "       [-0.38117992,  0.52992605, -2.23842543, ..., -0.07934091,\n",
       "         0.53751999,  1.14071072],\n",
       "       ...,\n",
       "       [ 0.95189498, -0.4362282 ,  0.8394476 , ...,  0.93333885,\n",
       "        -0.67172727, -0.35164509],\n",
       "       [-1.14084966,  0.63102523,  0.39776863, ...,  0.27830513,\n",
       "         1.93750669, -0.78038545],\n",
       "       [ 0.78509044, -0.52310864,  0.81127777, ...,  0.76926298,\n",
       "        -0.62738451, -0.49095059]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd4dadd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_pred=model.predict(Xtest)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26d53872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9999928e-01],\n",
       "       [2.9640076e-01],\n",
       "       [6.5919794e-03],\n",
       "       ...,\n",
       "       [1.0000000e+00],\n",
       "       [1.5473318e-28],\n",
       "       [9.9999994e-01]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d44d6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundoff(x):\n",
    "  if x>0.5:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01f3cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predround=np.array([roundoff(x) for x in Y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a58a613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "083e91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.DataFrame(Y_predround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66ccebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv(\"submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
